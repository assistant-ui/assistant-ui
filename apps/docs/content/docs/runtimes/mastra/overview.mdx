---
title: Overview
---

Mastra is an open-source TypeScript agent framework designed to provide the essential primitives for building AI applications. It enables developers to create AI agents with memory and tool-calling capabilities, implement deterministic LLM workflows, and leverage RAG for knowledge integration. With features like model routing, workflow graphs, and automated evals, Mastra provides a complete toolkit for developing, testing, and deploying AI applications.

## Quick Start

Install the dedicated Mastra integration package:

```bash npm2yarn
npm install @assistant-ui/react-mastra @mastra/core @mastra/memory
```

Create a simple chat interface with Mastra agents:

```tsx
"use client";

import { Thread } from "@/components/assistant-ui/thread";
import { AssistantRuntimeProvider } from "@assistant-ui/react";
import { useMastraRuntime } from "@assistant-ui/react-mastra";

export default function Home() {
  const runtime = useMastraRuntime({
    agentId: "chef-agent",
    memory: true,
  });

  return (
    <AssistantRuntimeProvider runtime={runtime}>
      <div className="h-full">
        <Thread />
      </div>
    </AssistantRuntimeProvider>
  );
}
```

## Features

### ü§ñ **Agent System**
- **Intelligent Agents**: Memory-enabled agents with persistent context and tool-calling
- **Model Routing**: Support for 600+ models via unified provider API
- **Dynamic Tool Integration**: Automatic function registration and execution
- **Multi-Agent Orchestration**: Agent communication and composition patterns

### üîÄ **Workflow Orchestration**
- **XState-Powered Workflows**: Deterministic graph-based state machines
- **Advanced Control Flow**: `.then()`, `.branch()`, `.parallel()`, `.suspend()`, `.resume()`
- **Human-in-the-Loop**: Suspend/resume workflows with real-time state streaming

### üß† **Memory Management**
- **Persistent Memory**: Thread-based storage with semantic recall capabilities
- **Vector-Based Search**: Context retrieval using similarity and metadata filtering
- **Multiple Storage Backends**: LibSQL, PostgreSQL, Turso, Pinecone, Chroma integration

### üîç **RAG Pipeline**
- **Multi-Format Processing**: Text, HTML, Markdown, JSON with intelligent chunking
- **Unified Vector Store API**: Consistent interface across all vector providers
- **Advanced Filtering**: Source, time-based, and custom metadata filtering

### üìä **Observability & Monitoring**
- **AI-Specific Tracing**: Specialized tracing for agents, LLM calls, tool executions
- **Performance Metrics**: Token usage, latency, accuracy, relevance tracking
- **Multi-Platform Export**: Langfuse, Braintrust, LangSmith, OpenTelemetry integration

### ‚úÖ **Evaluation System**
- **Automated Evaluation**: Model-graded, rule-based, and statistical evaluation methods
- **Comprehensive Metrics**: Toxicity, bias, relevance, factual accuracy assessment
- **CI/CD Integration**: Automated evaluation in deployment pipelines

## Integrating with Next.js and assistant-ui

There are two primary ways to integrate Mastra into your Next.js project when using assistant-ui:

1.  **Full-Stack Integration**: Integrate Mastra directly into your Next.js application's API routes. This approach keeps your backend and frontend code within the same project.
    [Learn how to set up Full-Stack Integration](./full-stack-integration)

2.  **Separate Server Integration**: Run Mastra as a standalone server and connect your Next.js frontend to its API endpoints. This approach separates concerns and allows for independent scaling.
    [Learn how to set up Separate Server Integration](./separate-server-integration)

Choose the guide that best fits your project architecture. Both methods allow seamless integration with the assistant-ui components.
